{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00c267e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision.transforms as T\n",
    "from torchvision.transforms.functional import InterpolationMode\n",
    "import torch.nn as nn\n",
    "import timm\n",
    "import torch_pruning as tp\n",
    "\n",
    "import pbench\n",
    "pbench.forward_patch.patch_timm_forward() # patch timm.forward() to support pruning\n",
    "\n",
    "from tqdm import tqdm\n",
    "import argparse\n",
    "\n",
    "import torchvision as tv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23e85d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Subset\n",
    "import random\n",
    "\n",
    "def prepare_imagenet(imagenet_root, train_batch_size=64, val_batch_size=128, num_workers=4, use_imagenet_mean_std=True, interpolation='bicubic', val_resize=256):\n",
    "    \"\"\"The imagenet_root should contain train and val folders.\n",
    "    \"\"\"\n",
    "    interpolation = getattr(T.InterpolationMode, interpolation.upper())\n",
    "\n",
    "    print('Parsing dataset...')\n",
    "    train_dst = ImageFolder(os.path.join(imagenet_root, 'train'), \n",
    "                            transform=pbench.data.presets.ClassificationPresetEval(\n",
    "                                mean=[0.485, 0.456, 0.406] if use_imagenet_mean_std else [0.5, 0.5, 0.5],\n",
    "                                std=[0.229, 0.224, 0.225] if use_imagenet_mean_std else [0.5, 0.5, 0.5],\n",
    "                                crop_size=224,\n",
    "                                resize_size=val_resize,\n",
    "                                interpolation=interpolation,\n",
    "                            )\n",
    "    )\n",
    "    val_dst = ImageFolder(os.path.join(imagenet_root, 'val'), \n",
    "                          transform=pbench.data.presets.ClassificationPresetEval(\n",
    "                                mean=[0.485, 0.456, 0.406] if use_imagenet_mean_std else [0.5, 0.5, 0.5],\n",
    "                                std=[0.229, 0.224, 0.225] if use_imagenet_mean_std else [0.5, 0.5, 0.5],\n",
    "                                crop_size=224,\n",
    "                                resize_size=val_resize,\n",
    "                                interpolation=interpolation,\n",
    "                            )\n",
    "    )\n",
    "    train_loader = torch.utils.data.DataLoader(train_dst, batch_size=train_batch_size, shuffle=True, num_workers=num_workers)\n",
    "    val_loader = torch.utils.data.DataLoader(val_dst, batch_size=val_batch_size, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "    cal_subset_size = 1024\n",
    "    cal_indices = random.sample(range(len(val_loader)*val_batch_size), cal_subset_size)\n",
    "    cal_dst = Subset(val_dst, cal_indices)\n",
    "    cal_loader = torch.utils.data.DataLoader(cal_dst, batch_size=val_batch_size, shuffle=False, num_workers=num_workers)\n",
    "    \n",
    "    return train_loader, val_loader, cal_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b17d297e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "def validate_model(model, val_loader, device):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    correct = 0\n",
    "    loss = 0\n",
    "    with torch.no_grad():\n",
    "        for k, (images, labels) in enumerate(tqdm(val_loader)):  \n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss += torch.nn.functional.cross_entropy(outputs, labels, reduction='sum').item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    del images, outputs, predicted\n",
    "    gc.collect()\n",
    "    return correct / len(val_loader.dataset), loss / len(val_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75b0efc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path ='data/imagenet'\n",
    "train_batch_size = 64\n",
    "val_batch_size = 1\n",
    "no_imagenet_mean_std = False\n",
    "val_resize = 256\n",
    "interpolation = 'bilinear' #'bicubic'\n",
    "\n",
    "model = 'resnet101.tv_in1k' #'mobilenet_v2' #'convnext_base.fb_in1k'\n",
    "is_torchvision = False\n",
    "drop = 0.0\n",
    "drop_path = 0.0\n",
    "ckpt = None\n",
    "\n",
    "taylor_batchs = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84c6485c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing dataset...\n",
      "Loading timm model resnet101.tv_in1k...\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "example_inputs = torch.randn(1,3,224,224)\n",
    "train_loader, val_loader, cal_loader = prepare_imagenet(data_path, train_batch_size=train_batch_size, val_batch_size=val_batch_size, use_imagenet_mean_std= not no_imagenet_mean_std, val_resize=val_resize, interpolation=interpolation)\n",
    "\n",
    "if is_torchvision:\n",
    "        import torchvision\n",
    "        print(f\"Loading torchvision model {model}...\")\n",
    "        model = torchvision.models.__dict__[model](pretrained=True).eval()\n",
    "else:\n",
    "    print(f\"Loading timm model {model}...\")\n",
    "    model = timm.create_model(model, pretrained=True, drop_rate=drop, drop_path_rate=drop_path).eval()\n",
    "\n",
    "if ckpt is not None:\n",
    "    print(f\"Loading checkpoint from {ckpt}...\")\n",
    "    ckpt = torch.load(ckpt, map_location='cpu')\n",
    "    model.load_state_dict(ckpt['model'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aab19ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_resnet_blocks(model):\n",
    "\n",
    "    model_blocks, ignored_blocks = [], []\n",
    "\n",
    "    for child in model.children():\n",
    "        if isinstance(child, nn.Sequential):\n",
    "            model_blocks.extend([sub_child for sub_child in child.children()])\n",
    "        else:\n",
    "            ignored_blocks.append(child)\n",
    "\n",
    "    return model_blocks, ignored_blocks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5279f75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mobilenet_blocks(model):\n",
    "\n",
    "    model_blocks, ignored_blocks = [], []\n",
    "\n",
    "    for feat in model.features:\n",
    "        if not isinstance(feat, nn.Sequential):\n",
    "            model_blocks.append(feat)\n",
    "        else:\n",
    "            ignored_blocks.append(feat)\n",
    "\n",
    "    ignored_blocks.append(model.classifier)\n",
    "\n",
    "    return model_blocks, ignored_blocks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34106bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_convnext_blocks(model):\n",
    "\n",
    "      model_blocks, ignored_blocks = [], []\n",
    "\n",
    "      for stage in model.stages:\n",
    "            for block in stage.blocks:\n",
    "                  if isinstance(block, nn.Module):\n",
    "                        model_blocks.append(block)\n",
    "            model_blocks.append(stage.downsample)\n",
    "\n",
    "      ignored_blocks.extend([model.stem, model.norm_pre, model.head])\n",
    "\n",
    "      return model_blocks, ignored_blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "74eb773e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_blocks(model):\n",
    "    if model.__class__.__name__ == \"MobileNetV2\":\n",
    "        return get_mobilenet_blocks(model)\n",
    "    elif model.__class__.__name__ == \"ResNet\":\n",
    "        return get_resnet_blocks(model)\n",
    "    elif model.__class__.__name__ == \"ConvNeXt\":\n",
    "        return get_convnext_blocks(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d8183c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import warnings\n",
    "\n",
    "def selective_block_pruning(trained_model, prune_method, pruning_ratios, data_loader, device):\n",
    "    \n",
    "\n",
    "    model = copy.deepcopy(trained_model)\n",
    "    model_blocks, ignored_layers = get_model_blocks(model)\n",
    "    model.to(device)\n",
    "\n",
    "    pruning_info = {i: {\"block\": model_blocks[i], \"pruning_ratio\": ratio} for i, ratio in enumerate(pruning_ratios)}\n",
    "\n",
    "    if prune_method == \"Taylor\":\n",
    "        imp = tp.importance.TaylorImportance()\n",
    "\n",
    "        if isinstance(imp, (tp.importance.GroupTaylorImportance, tp.importance.GroupHessianImportance)):\n",
    "            model.zero_grad()\n",
    "            if isinstance(imp, tp.importance.GroupHessianImportance):\n",
    "                imp.zero_grad() # clear the accumulated gradients\n",
    "            print(\"Accumulating gradients for pruning...\")\n",
    "            for k, (imgs, lbls) in enumerate(tqdm(data_loader)):\n",
    "                if k>=taylor_batchs: break\n",
    "                imgs = imgs.to(device)\n",
    "                lbls = lbls.to(device)\n",
    "                output = model(imgs)\n",
    "                if isinstance(imp, tp.importance.GroupHessianImportance): # per-sample gradients for hessian\n",
    "                    loss = torch.nn.functional.cross_entropy(output, lbls, reduction='none')\n",
    "                    for l in loss:\n",
    "                        model.zero_grad()\n",
    "                        l.backward(retain_graph=True)\n",
    "                        imp.accumulate_grad(model) # accumulate gradients\n",
    "                elif isinstance(imp, tp.importance.GroupTaylorImportance): # batch gradients for first-order taylor\n",
    "                    loss = torch.nn.functional.cross_entropy(output, lbls)\n",
    "                    loss.backward()\n",
    "\n",
    "    elif prune_method == \"Magnitude\":\n",
    "        imp = tp.importance.MagnitudeImportance()\n",
    "\n",
    "    else:\n",
    "        warnings.warn(f\"Invalid pruning method: '{prune_method}'. Expected 'Taylor' or 'Magnitude'.\", UserWarning)\n",
    "        raise ValueError(\"Pruning method must be either 'Taylor' or 'Magnitude'.\")\n",
    "\n",
    "    _, original_nparams = tp.utils.count_ops_and_params(model, imgs)\n",
    "\n",
    "    for i, info in pruning_info.items():\n",
    "        _, pruning_ratio = info[\"block\"], info[\"pruning_ratio\"]\n",
    "        if pruning_ratio == 0.0:\n",
    "            continue\n",
    "\n",
    "        ignored_layers_block = [pruning_info[j][\"block\"] for j in range(len(pruning_info)) if j != i]\n",
    "        combined_ignored_layers = ignored_layers + ignored_layers_block\n",
    "\n",
    "        count = 0\n",
    "\n",
    "        while True:\n",
    "\n",
    "            pruner_group = tp.pruner.MagnitudePruner(\n",
    "                model,\n",
    "                example_inputs=imgs,\n",
    "                importance=imp,\n",
    "                pruning_ratio=pruning_ratio,\n",
    "                ignored_layers=combined_ignored_layers,\n",
    "            )\n",
    "            pruner_group.step()\n",
    "\n",
    "            macs, nparams = tp.utils.count_ops_and_params(model, imgs)\n",
    "            if original_nparams - nparams == 0:\n",
    "                count += 1\n",
    "                if count > 1:\n",
    "                    break\n",
    "                pruning_ratio = 0.5\n",
    "\n",
    "            original_nparams = nparams\n",
    "\n",
    "    del imgs, lbls, output\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "    return model, macs, nparams\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d7712cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def perplexity_analysis_with_contributions(original_model, prune_method, data_loader, device):\n",
    "\n",
    "    \n",
    "    model_blocks, ignored_layers = get_model_blocks(original_model)\n",
    "    blocks_number = len(model_blocks)\n",
    "\n",
    "    total_block_accuracy = [0.0 for _ in range(blocks_number)]\n",
    "    params_reduction = []\n",
    "    macs_reduction = []\n",
    "\n",
    "    # logging.info(\"\\n=== Computing baseline accuracy without block replacement ===\")\n",
    "    print(\"\\n=== Computing baseline accuracy without block replacement ===\")\n",
    "    baseline_accuracy, baseline_loss = validate_model(original_model, data_loader, device='cpu')\n",
    "    # logging.info(f\"Baseline accuracy: {baseline_accuracy*100:.2f}%\")\n",
    "    print(f\"Baseline accuracy: {baseline_accuracy*100:.2f}%\")\n",
    "    \n",
    "    input_size = [3, 224, 224]\n",
    "    example_inputs = torch.randn(1, *input_size)\n",
    "    original_macs, original_nparams = tp.utils.count_ops_and_params(original_model, example_inputs)\n",
    "\n",
    "\n",
    "    for block_idx in range(blocks_number):\n",
    "\n",
    "        # logging.info(\"\\n=== Replacing Blocks and Tracking Reductions ===\")\n",
    "        print(\"\\n=== Replacing Blocks and Tracking Reductions ===\")\n",
    "\n",
    "        pruning_ratios = (np.eye(blocks_number) * 0.8)[block_idx]\n",
    "\n",
    "        pruned_model, macs, nparams = selective_block_pruning(\n",
    "        original_model, prune_method, pruning_ratios, data_loader, device\n",
    "        )\n",
    "\n",
    "        # logging.info(f\"\\nReplacing Block {block_idx}:\")\n",
    "        # logging.info(f\"  - MACs Reduction: {((original_macs - macs) / original_macs * 100):.2f}%\")\n",
    "        # logging.info(f\"  - Parameters Reduction: {((original_nparams - nparams)/original_nparams*100):.2f}%\")\n",
    "        print(f\"\\nReplacing Block {block_idx}:\")\n",
    "        print(f\"  - MACs Reduction: {((original_macs - macs) / original_macs * 100):.2f}%\")\n",
    "        print(f\"  - Parameters Reduction: {((original_nparams - nparams)/original_nparams*100):.2f}%\")\n",
    "\n",
    "        params_reduction.append(original_nparams - nparams)\n",
    "        macs_reduction.append(original_macs - macs)\n",
    "\n",
    "        pruned_model.to(device)\n",
    "        pruned_model.eval()\n",
    "        \n",
    "        pruned_accuracy,_ = validate_model(pruned_model, data_loader, device='cpu')\n",
    "\n",
    "        del pruned_model\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        logging.info(f\"Accuracy After Pruning This Block: {pruned_accuracy*100:.2f}%\\n\")\n",
    "        total_block_accuracy[block_idx] += pruned_accuracy\n",
    "\n",
    "    total_accuracy_reduction = 0.0\n",
    "    block_reductions = []\n",
    "    total_params_reduction = 0.0\n",
    "    total_macs_reduction = 0.0\n",
    "\n",
    "    for block_idx in range(blocks_number):\n",
    "        final_average_accuracy = total_block_accuracy[block_idx]\n",
    "        accuracy_reduction = baseline_accuracy - final_average_accuracy\n",
    "        block_reductions.append(accuracy_reduction)\n",
    "        total_accuracy_reduction += accuracy_reduction\n",
    "        total_params_reduction += params_reduction[block_idx]\n",
    "        total_macs_reduction += macs_reduction[block_idx] \n",
    "\n",
    "    relative_contributions = []\n",
    "    weighted_importance_scores = []\n",
    "\n",
    "    # logging.info(\"\\n=== Relative Contribution of Each Block ===\")\n",
    "    print(\"\\n=== Relative Contribution of Each Block ===\")\n",
    "    for block_idx in range(blocks_number):\n",
    "        relative_contribution_accuracy = (block_reductions[block_idx] / total_accuracy_reduction) * 100\n",
    "        relative_contribution_params = (1 - (params_reduction[block_idx] / total_params_reduction)) * 100\n",
    "        relative_contribution_macs = (1 - (macs_reduction[block_idx] / total_macs_reduction)) * 100\n",
    "\n",
    "        weight_accuracy = 0.5\n",
    "        weight_params = 0.3\n",
    "        weight_macs = 0.2\n",
    "        weighted_importance = (weight_accuracy * relative_contribution_accuracy) \n",
    "        + (weight_params * relative_contribution_params) \n",
    "        + (weight_macs * relative_contribution_macs)\n",
    "\n",
    "        # logging.info(\n",
    "        # f\"Block {block_idx}: Accuracy Decrease Contribution = {relative_contribution_accuracy:.2f}%, \"\n",
    "        # f\"Parameter Reduction = {100 - relative_contribution_params:.2f}%, \"\n",
    "        # f\"MACs Reduction = {100 - relative_contribution_macs:.2f}%, \"\n",
    "        # f\"Weighted Importance Score = {weighted_importance:.2f}\"\n",
    "        # )  \n",
    "        print(f\"Block {block_idx}: Accuracy Decrease Contribution = {relative_contribution_accuracy:.2f}%, \")\n",
    "        print(f\"Parameter Reduction = {100 - relative_contribution_params:.2f}%, \")\n",
    "        print(f\"MACs Reduction = {100 - relative_contribution_macs:.2f}%, \")\n",
    "        print(f\"Weighted Importance Score = {weighted_importance:.2f}\") \n",
    "\n",
    "        relative_contributions.append(relative_contribution_accuracy)\n",
    "        weighted_importance_scores.append(weighted_importance)\n",
    "\n",
    "    return weighted_importance_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "624deb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import logging\n",
    "# import numpy as np\n",
    "\n",
    "\n",
    "# def perplexity_analysis_with_contributions(original_model, prune_method, data_loader, device):\n",
    "\n",
    "    \n",
    "#     model_blocks, ignored_layers = get_model_blocks(original_model)\n",
    "#     blocks_number = len(model_blocks)\n",
    "\n",
    "#     total_block_accuracy = [0.0 for _ in range(blocks_number)]\n",
    "#     params_reduction = []\n",
    "#     macs_reduction = []\n",
    "\n",
    "#     # logging.info(\"\\n=== Computing baseline accuracy without block replacement ===\")\n",
    "#     print(\"\\n=== Computing baseline accuracy without block replacement ===\")\n",
    "#     baseline_accuracy, baseline_loss = validate_model(original_model, data_loader, device='cpu')\n",
    "#     # logging.info(f\"Baseline accuracy: {baseline_accuracy*100:.2f}%\")\n",
    "#     print(f\"Baseline accuracy: {baseline_accuracy*100:.2f}%\")\n",
    "    \n",
    "#     input_size = [3, 224, 224]\n",
    "#     example_inputs = torch.randn(1, *input_size).to(device)\n",
    "#     original_macs, original_nparams = tp.utils.count_ops_and_params(original_model, example_inputs)\n",
    "\n",
    "\n",
    "#     # logging.info(\"\\n=== Replacing Blocks and Tracking Reductions ===\")\n",
    "#     print(\"\\n=== Replacing Blocks and Tracking Reductions ===\")\n",
    "\n",
    "#     # pruning_ratios = (np.eye(blocks_number) * 0.8)[block_idx]\n",
    "\n",
    "#     pruned_acc, pruned_macs, pruned_params = selective_block_pruning(\n",
    "#     original_model, prune_method, data_loader, device\n",
    "#     )\n",
    "\n",
    "#     # logging.info(f\"\\nReplacing Block {block_idx}:\")\n",
    "#     # logging.info(f\"  - MACs Reduction: {((original_macs - macs) / original_macs * 100):.2f}%\")\n",
    "#     # logging.info(f\"  - Parameters Reduction: {((original_nparams - nparams)/original_nparams*100):.2f}%\")\n",
    "\n",
    "#     params_reduction = [original_nparams - param for param in pruned_params]\n",
    "#     macs_reduction = [original_macs - macs for macs in pruned_macs]\n",
    "\n",
    "#     # pruned_model.to(device)\n",
    "#     # pruned_model.eval()\n",
    "    \n",
    "#     # pruned_accuracy,_ = validate_model(pruned_model, data_loader, device='cpu')\n",
    "\n",
    "#     # del pruned_model\n",
    "#     # torch.cuda.empty_cache()\n",
    "\n",
    "#     # logging.info(f\"Accuracy After Pruning This Block: {nacc*100:.2f}%\\n\")\n",
    "#     total_block_accuracy = pruned_acc\n",
    "\n",
    "#     total_accuracy_reduction = 0.0\n",
    "#     block_reductions = []\n",
    "#     total_params_reduction = 0.0\n",
    "#     total_macs_reduction = 0.0\n",
    "\n",
    "#     for block_idx in range(blocks_number):\n",
    "#         final_average_accuracy = total_block_accuracy[block_idx]\n",
    "#         accuracy_reduction = baseline_accuracy - final_average_accuracy\n",
    "#         block_reductions.append(accuracy_reduction)\n",
    "#         total_accuracy_reduction += accuracy_reduction\n",
    "#         total_params_reduction += params_reduction[block_idx]\n",
    "#         total_macs_reduction += macs_reduction[block_idx] \n",
    "\n",
    "#     relative_contributions = []\n",
    "#     weighted_importance_scores = []\n",
    "\n",
    "#     # logging.info(\"\\n=== Relative Contribution of Each Block ===\")\n",
    "#     print(\"\\n=== Relative Contribution of Each Block ===\")\n",
    "#     for block_idx in range(blocks_number):\n",
    "#         relative_contribution_accuracy = (block_reductions[block_idx] / total_accuracy_reduction) * 100\n",
    "#         relative_contribution_params = (1 - (params_reduction[block_idx] / total_params_reduction)) * 100\n",
    "#         relative_contribution_macs = (1 - (macs_reduction[block_idx] / total_macs_reduction)) * 100\n",
    "\n",
    "#         weight_accuracy = 0.5\n",
    "#         weight_params = 0.3\n",
    "#         weight_macs = 0.2\n",
    "#         weighted_importance = (weight_accuracy * relative_contribution_accuracy) \n",
    "#         + (weight_params * relative_contribution_params) \n",
    "#         + (weight_macs * relative_contribution_macs)\n",
    "\n",
    "#         logging.info(\n",
    "#         f\"Block {block_idx}: Accuracy Decrease Contribution = {relative_contribution_accuracy:.2f}%, \"\n",
    "#         f\"Parameter Reduction = {100 - relative_contribution_params:.2f}%, \"\n",
    "#         f\"MACs Reduction = {100 - relative_contribution_macs:.2f}%, \"\n",
    "#         f\"Weighted Importance Score = {weighted_importance:.2f}\"\n",
    "#         )  \n",
    "#         print(f\"Block {block_idx}: Accuracy Decrease Contribution = {relative_contribution_accuracy:.2f}%, \")\n",
    "#         print(f\"Parameter Reduction = {100 - relative_contribution_params:.2f}%, \")\n",
    "#         print(f\"MACs Reduction = {100 - relative_contribution_macs:.2f}%, \")\n",
    "#         print(f\"Weighted Importance Score = {weighted_importance:.2f}\")\n",
    "\n",
    "#         relative_contributions.append(relative_contribution_accuracy)\n",
    "#         weighted_importance_scores.append(weighted_importance)\n",
    "\n",
    "#     return weighted_importance_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c4c1deff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_model(trained_model, prune_method, pruning_ratios, data_loader, device):\n",
    "   \n",
    "    # Make a copy of the trained model\n",
    "    model = copy.deepcopy(trained_model)\n",
    "    model.to(device)\n",
    "\n",
    "    model_blocks, ignored_layers = get_model_blocks(model)\n",
    "\n",
    "\n",
    "    pruning_info = {i: {\"block\": model_blocks[i], \"pruning_ratio\": ratio} \n",
    "                    for i, ratio in enumerate(pruning_ratios)}\n",
    "\n",
    "    if prune_method == 'Taylor':\n",
    "        imp = tp.importance.TaylorImportance() \n",
    "        \n",
    "        if isinstance(imp, (tp.importance.GroupTaylorImportance, tp.importance.GroupHessianImportance)):\n",
    "            model.zero_grad()\n",
    "            if isinstance(imp, tp.importance.GroupHessianImportance):\n",
    "                imp.zero_grad() # clear the accumulated gradients\n",
    "            print(\"Accumulating gradients for pruning...\")\n",
    "            for k, (imgs, lbls) in enumerate(tqdm(data_loader)):\n",
    "                if k>=taylor_batchs: break\n",
    "                imgs = imgs.to(device)\n",
    "                lbls = lbls.to(device)\n",
    "                output = model(imgs)\n",
    "                if isinstance(imp, tp.importance.GroupHessianImportance): # per-sample gradients for hessian\n",
    "                    loss = torch.nn.functional.cross_entropy(output, lbls, reduction='none')\n",
    "                    for l in loss:\n",
    "                        model.zero_grad()\n",
    "                        l.backward(retain_graph=True)\n",
    "                        imp.accumulate_grad(model) # accumulate gradients\n",
    "                elif isinstance(imp, tp.importance.GroupTaylorImportance): # batch gradients for first-order taylor\n",
    "                    loss = torch.nn.functional.cross_entropy(output, lbls)\n",
    "                    loss.backward()\n",
    "\n",
    "        original_macs, original_params = tp.utils.count_ops_and_params(model, imgs)\n",
    "\n",
    "        # Prune each block while ignoring other layers\n",
    "        for i, info in pruning_info.items():\n",
    "            pruning_ratio = info[\"pruning_ratio\"]\n",
    "            \n",
    "            # Add all blocks to the ignored layers except the block being pruned\n",
    "            ignored_layers_block = [pruning_info[j][\"block\"] for j in range(len(pruning_info)) if j != i]\n",
    "\n",
    "            # Combine fixed ignored layers (conv_stem, bn1, classifier) with the ignored blocks\n",
    "            combined_ignored_layers = ignored_layers + ignored_layers_block\n",
    "\n",
    "            # Apply pruning using the combined ignored layers\n",
    "            pruner_group = tp.pruner.MagnitudePruner( \n",
    "                model,\n",
    "                example_inputs=imgs,\n",
    "                importance=imp,\n",
    "                pruning_ratio=pruning_ratio,\n",
    "                ignored_layers=combined_ignored_layers,\n",
    "                iterative_steps=1,\n",
    "            )\n",
    "\n",
    "            # Step through pruning\n",
    "            pruner_group.step()\n",
    "\n",
    "    # Counting MACs and Params after pruning\n",
    "    macs, nparams = tp.utils.count_ops_and_params(model, imgs)\n",
    "\n",
    "    # logging.info(f\"MACs of the Pruned Model: {macs/ 1e9} G\")\n",
    "    print(f\"MACs of the Original Model: {original_macs/ 1e9} G  -->  MACs of the Pruned Model: {macs/ 1e9} G\")\n",
    "    # logging.info(f\"# Parameters of the Pruned Model: {nparams/ 1e3} K\")\n",
    "    print(f\"# Parameters of the Original Model: {original_params/ 1e3} K  --> # Parameters of the Pruned Model: {nparams/ 1e3} K\")\n",
    "\n",
    "    # Free up GPU memory\n",
    "    del imgs, lbls, output\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "43909cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_pruning_ratios_intense(contributions, max_pruning_ratio=0.9, k=5):\n",
    "    # Normalize the contributions to get values between 0 and 1\n",
    "    total_contribution = sum(contributions)\n",
    "    normalized_contributions = [contribution / total_contribution for contribution in contributions]\n",
    "\n",
    "    # Apply exponential decay to magnify the effect for less important blocks\n",
    "    pruning_factors = [np.exp(-k * nc) for nc in normalized_contributions]\n",
    "\n",
    "    # Normalize the pruning factors so they stay within the max pruning ratio\n",
    "    max_factor = max(pruning_factors)\n",
    "    normalized_factors = [pf / max_factor for pf in pruning_factors]\n",
    "\n",
    "    # Scale by the maximum pruning ratio\n",
    "    pruning_ratios = [max_pruning_ratio * nf for nf in normalized_factors]\n",
    "\n",
    "    pruning_ratios = [round(num, 2) for num in pruning_ratios]\n",
    "\n",
    "    return pruning_ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ac8bbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Computing baseline accuracy without block replacement ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:46<00:00,  2.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline accuracy: 84.47%\n",
      "\n",
      "=== Replacing Blocks and Tracking Reductions ===\n",
      "Accumulating gradients for pruning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:10<00:00, 12.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Replacing Block 0:\n",
      "  - MACs Reduction: 2.67%\n",
      "  - Parameters Reduction: 0.15%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:43<00:00,  2.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Replacing Blocks and Tracking Reductions ===\n",
      "Accumulating gradients for pruning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:10<00:00, 12.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Replacing Block 1:\n",
      "  - MACs Reduction: 2.67%\n",
      "  - Parameters Reduction: 0.15%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:44<00:00,  2.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Replacing Blocks and Tracking Reductions ===\n",
      "Accumulating gradients for pruning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:10<00:00, 12.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Replacing Block 2:\n",
      "  - MACs Reduction: 2.67%\n",
      "  - Parameters Reduction: 0.15%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:43<00:00,  2.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Replacing Blocks and Tracking Reductions ===\n",
      "Accumulating gradients for pruning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:10<00:00, 12.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Replacing Block 3:\n",
      "  - MACs Reduction: 0.00%\n",
      "  - Parameters Reduction: 0.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:46<00:00,  2.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Replacing Blocks and Tracking Reductions ===\n",
      "Accumulating gradients for pruning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:09<00:00, 12.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Replacing Block 4:\n",
      "  - MACs Reduction: 2.67%\n",
      "  - Parameters Reduction: 0.59%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:45<00:00,  2.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Replacing Blocks and Tracking Reductions ===\n",
      "Accumulating gradients for pruning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:10<00:00, 12.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Replacing Block 5:\n",
      "  - MACs Reduction: 2.67%\n",
      "  - Parameters Reduction: 0.59%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:44<00:00,  2.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Replacing Blocks and Tracking Reductions ===\n",
      "Accumulating gradients for pruning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:10<00:00, 12.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Replacing Block 6:\n",
      "  - MACs Reduction: 2.67%\n",
      "  - Parameters Reduction: 0.59%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:44<00:00,  2.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Replacing Blocks and Tracking Reductions ===\n",
      "Accumulating gradients for pruning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:10<00:00, 12.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Replacing Block 7:\n",
      "  - MACs Reduction: 0.00%\n",
      "  - Parameters Reduction: 0.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:46<00:00,  2.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Replacing Blocks and Tracking Reductions ===\n",
      "Accumulating gradients for pruning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:09<00:00, 12.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Replacing Block 8:\n",
      "  - MACs Reduction: 2.68%\n",
      "  - Parameters Reduction: 2.37%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:45<00:00,  2.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Replacing Blocks and Tracking Reductions ===\n",
      "Accumulating gradients for pruning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:10<00:00, 12.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Replacing Block 9:\n",
      "  - MACs Reduction: 2.68%\n",
      "  - Parameters Reduction: 2.37%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:45<00:00,  2.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Replacing Blocks and Tracking Reductions ===\n",
      "Accumulating gradients for pruning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:10<00:00, 12.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Replacing Block 10:\n",
      "  - MACs Reduction: 2.68%\n",
      "  - Parameters Reduction: 2.37%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:45<00:00,  2.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Replacing Blocks and Tracking Reductions ===\n",
      "Accumulating gradients for pruning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:09<00:00, 12.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Replacing Block 11:\n",
      "  - MACs Reduction: 2.68%\n",
      "  - Parameters Reduction: 2.37%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:45<00:00,  2.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Replacing Blocks and Tracking Reductions ===\n",
      "Accumulating gradients for pruning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:09<00:00, 12.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Replacing Block 12:\n",
      "  - MACs Reduction: 2.68%\n",
      "  - Parameters Reduction: 2.37%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:45<00:00,  2.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Replacing Blocks and Tracking Reductions ===\n",
      "Accumulating gradients for pruning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:10<00:00, 12.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Replacing Block 13:\n",
      "  - MACs Reduction: 2.68%\n",
      "  - Parameters Reduction: 2.37%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:45<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Replacing Blocks and Tracking Reductions ===\n",
      "Accumulating gradients for pruning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:10<00:00, 12.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Replacing Block 14:\n",
      "  - MACs Reduction: 2.68%\n",
      "  - Parameters Reduction: 2.37%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:45<00:00,  2.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Replacing Blocks and Tracking Reductions ===\n",
      "Accumulating gradients for pruning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:09<00:00, 12.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Replacing Block 15:\n",
      "  - MACs Reduction: 2.68%\n",
      "  - Parameters Reduction: 2.37%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:45<00:00,  2.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Replacing Blocks and Tracking Reductions ===\n",
      "Accumulating gradients for pruning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:10<00:00, 12.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Replacing Block 16:\n",
      "  - MACs Reduction: 2.68%\n",
      "  - Parameters Reduction: 2.37%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:45<00:00,  2.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Replacing Blocks and Tracking Reductions ===\n",
      "Accumulating gradients for pruning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:09<00:00, 12.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Replacing Block 17:\n",
      "  - MACs Reduction: 2.68%\n",
      "  - Parameters Reduction: 2.37%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:45<00:00,  2.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Replacing Blocks and Tracking Reductions ===\n",
      "Accumulating gradients for pruning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:10<00:00, 12.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Replacing Block 18:\n",
      "  - MACs Reduction: 2.68%\n",
      "  - Parameters Reduction: 2.37%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:45<00:00,  2.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Replacing Blocks and Tracking Reductions ===\n",
      "Accumulating gradients for pruning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:10<00:00, 12.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Replacing Block 19:\n",
      "  - MACs Reduction: 2.68%\n",
      "  - Parameters Reduction: 2.37%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:45<00:00,  2.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Replacing Blocks and Tracking Reductions ===\n",
      "Accumulating gradients for pruning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:10<00:00, 12.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Replacing Block 20:\n",
      "  - MACs Reduction: 2.68%\n",
      "  - Parameters Reduction: 2.37%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:45<00:00,  2.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Replacing Blocks and Tracking Reductions ===\n",
      "Accumulating gradients for pruning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:10<00:00, 12.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Replacing Block 21:\n",
      "  - MACs Reduction: 2.68%\n",
      "  - Parameters Reduction: 2.37%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:44<00:00,  2.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Replacing Blocks and Tracking Reductions ===\n",
      "Accumulating gradients for pruning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:10<00:00, 12.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Replacing Block 22:\n",
      "  - MACs Reduction: 2.68%\n",
      "  - Parameters Reduction: 2.37%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:45<00:00,  2.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Replacing Blocks and Tracking Reductions ===\n",
      "Accumulating gradients for pruning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:09<00:00, 12.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Replacing Block 23:\n",
      "  - MACs Reduction: 2.68%\n",
      "  - Parameters Reduction: 2.37%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:45<00:00,  2.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Replacing Blocks and Tracking Reductions ===\n",
      "Accumulating gradients for pruning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:10<00:00, 12.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Replacing Block 24:\n",
      "  - MACs Reduction: 2.68%\n",
      "  - Parameters Reduction: 2.37%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:45<00:00,  2.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Replacing Blocks and Tracking Reductions ===\n",
      "Accumulating gradients for pruning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:09<00:00, 12.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Replacing Block 25:\n",
      "  - MACs Reduction: 2.68%\n",
      "  - Parameters Reduction: 2.37%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:45<00:00,  2.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Replacing Blocks and Tracking Reductions ===\n",
      "Accumulating gradients for pruning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:10<00:00, 12.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Replacing Block 26:\n",
      "  - MACs Reduction: 2.68%\n",
      "  - Parameters Reduction: 2.37%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:45<00:00,  2.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Replacing Blocks and Tracking Reductions ===\n",
      "Accumulating gradients for pruning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:10<00:00, 12.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Replacing Block 27:\n",
      "  - MACs Reduction: 2.68%\n",
      "  - Parameters Reduction: 2.37%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:45<00:00,  2.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Replacing Blocks and Tracking Reductions ===\n",
      "Accumulating gradients for pruning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:10<00:00, 12.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Replacing Block 28:\n",
      "  - MACs Reduction: 2.68%\n",
      "  - Parameters Reduction: 2.37%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:45<00:00,  2.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Replacing Blocks and Tracking Reductions ===\n",
      "Accumulating gradients for pruning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:10<00:00, 12.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Replacing Block 29:\n",
      "  - MACs Reduction: 2.68%\n",
      "  - Parameters Reduction: 2.37%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:45<00:00,  2.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Replacing Blocks and Tracking Reductions ===\n",
      "Accumulating gradients for pruning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:10<00:00, 12.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Replacing Block 30:\n",
      "  - MACs Reduction: 2.68%\n",
      "  - Parameters Reduction: 2.37%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:45<00:00,  2.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Replacing Blocks and Tracking Reductions ===\n",
      "Accumulating gradients for pruning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:10<00:00, 12.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Replacing Block 31:\n",
      "  - MACs Reduction: 2.68%\n",
      "  - Parameters Reduction: 2.37%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:45<00:00,  2.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Replacing Blocks and Tracking Reductions ===\n",
      "Accumulating gradients for pruning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:09<00:00, 12.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Replacing Block 32:\n",
      "  - MACs Reduction: 2.68%\n",
      "  - Parameters Reduction: 2.37%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:45<00:00,  2.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Replacing Blocks and Tracking Reductions ===\n",
      "Accumulating gradients for pruning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:10<00:00, 12.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Replacing Block 33:\n",
      "  - MACs Reduction: 2.68%\n",
      "  - Parameters Reduction: 2.37%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:45<00:00,  2.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Replacing Blocks and Tracking Reductions ===\n",
      "Accumulating gradients for pruning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:10<00:00, 12.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Replacing Block 34:\n",
      "  - MACs Reduction: 2.68%\n",
      "  - Parameters Reduction: 2.37%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:45<00:00,  2.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Replacing Blocks and Tracking Reductions ===\n",
      "Accumulating gradients for pruning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:10<00:00, 12.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Replacing Block 35:\n",
      "  - MACs Reduction: 0.00%\n",
      "  - Parameters Reduction: 0.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:46<00:00,  2.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Replacing Blocks and Tracking Reductions ===\n",
      "Accumulating gradients for pruning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:10<00:00, 12.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Replacing Block 36:\n",
      "  - MACs Reduction: 2.68%\n",
      "  - Parameters Reduction: 9.47%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:45<00:00,  2.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Replacing Blocks and Tracking Reductions ===\n",
      "Accumulating gradients for pruning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:10<00:00, 12.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Replacing Block 37:\n",
      "  - MACs Reduction: 2.68%\n",
      "  - Parameters Reduction: 9.47%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:45<00:00,  2.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Replacing Blocks and Tracking Reductions ===\n",
      "Accumulating gradients for pruning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:10<00:00, 12.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Replacing Block 38:\n",
      "  - MACs Reduction: 2.68%\n",
      "  - Parameters Reduction: 9.47%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:45<00:00,  2.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Replacing Blocks and Tracking Reductions ===\n",
      "Accumulating gradients for pruning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:10<00:00, 12.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Replacing Block 39:\n",
      "  - MACs Reduction: 0.00%\n",
      "  - Parameters Reduction: 0.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:46<00:00,  2.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Relative Contribution of Each Block ===\n",
      "Block 0: Accuracy Decrease Contribution = 59.03%, \n",
      "Parameter Reduction = 0.16%, \n",
      "MACs Reduction = 2.77%, \n",
      "Weighted Importance Score = 29.51\n",
      "Block 1: Accuracy Decrease Contribution = 3.50%, \n",
      "Parameter Reduction = 0.16%, \n",
      "MACs Reduction = 2.77%, \n",
      "Weighted Importance Score = 1.75\n",
      "Block 2: Accuracy Decrease Contribution = 9.43%, \n",
      "Parameter Reduction = 0.16%, \n",
      "MACs Reduction = 2.77%, \n",
      "Weighted Importance Score = 4.72\n",
      "Block 3: Accuracy Decrease Contribution = 0.00%, \n",
      "Parameter Reduction = 0.00%, \n",
      "MACs Reduction = 0.00%, \n",
      "Weighted Importance Score = 0.00\n",
      "Block 4: Accuracy Decrease Contribution = 1.62%, \n",
      "Parameter Reduction = 0.63%, \n",
      "MACs Reduction = 2.78%, \n",
      "Weighted Importance Score = 0.81\n",
      "Block 5: Accuracy Decrease Contribution = 1.89%, \n",
      "Parameter Reduction = 0.63%, \n",
      "MACs Reduction = 2.78%, \n",
      "Weighted Importance Score = 0.94\n",
      "Block 6: Accuracy Decrease Contribution = 1.62%, \n",
      "Parameter Reduction = 0.63%, \n",
      "MACs Reduction = 2.78%, \n",
      "Weighted Importance Score = 0.81\n",
      "Block 7: Accuracy Decrease Contribution = 0.00%, \n",
      "Parameter Reduction = 0.00%, \n",
      "MACs Reduction = 0.00%, \n",
      "Weighted Importance Score = 0.00\n",
      "Block 8: Accuracy Decrease Contribution = -0.81%, \n",
      "Parameter Reduction = 2.50%, \n",
      "MACs Reduction = 2.78%, \n",
      "Weighted Importance Score = -0.40\n",
      "Block 9: Accuracy Decrease Contribution = 1.62%, \n",
      "Parameter Reduction = 2.50%, \n",
      "MACs Reduction = 2.78%, \n",
      "Weighted Importance Score = 0.81\n",
      "Block 10: Accuracy Decrease Contribution = 1.08%, \n",
      "Parameter Reduction = 2.50%, \n",
      "MACs Reduction = 2.78%, \n",
      "Weighted Importance Score = 0.54\n",
      "Block 11: Accuracy Decrease Contribution = 2.16%, \n",
      "Parameter Reduction = 2.50%, \n",
      "MACs Reduction = 2.78%, \n",
      "Weighted Importance Score = 1.08\n",
      "Block 12: Accuracy Decrease Contribution = 1.62%, \n",
      "Parameter Reduction = 2.50%, \n",
      "MACs Reduction = 2.78%, \n",
      "Weighted Importance Score = 0.81\n",
      "Block 13: Accuracy Decrease Contribution = -0.54%, \n",
      "Parameter Reduction = 2.50%, \n",
      "MACs Reduction = 2.78%, \n",
      "Weighted Importance Score = -0.27\n",
      "Block 14: Accuracy Decrease Contribution = 1.62%, \n",
      "Parameter Reduction = 2.50%, \n",
      "MACs Reduction = 2.78%, \n",
      "Weighted Importance Score = 0.81\n",
      "Block 15: Accuracy Decrease Contribution = -1.08%, \n",
      "Parameter Reduction = 2.50%, \n",
      "MACs Reduction = 2.78%, \n",
      "Weighted Importance Score = -0.54\n",
      "Block 16: Accuracy Decrease Contribution = -0.27%, \n",
      "Parameter Reduction = 2.50%, \n",
      "MACs Reduction = 2.78%, \n",
      "Weighted Importance Score = -0.13\n",
      "Block 17: Accuracy Decrease Contribution = 2.16%, \n",
      "Parameter Reduction = 2.50%, \n",
      "MACs Reduction = 2.78%, \n",
      "Weighted Importance Score = 1.08\n",
      "Block 18: Accuracy Decrease Contribution = 0.54%, \n",
      "Parameter Reduction = 2.50%, \n",
      "MACs Reduction = 2.78%, \n",
      "Weighted Importance Score = 0.27\n",
      "Block 19: Accuracy Decrease Contribution = 1.62%, \n",
      "Parameter Reduction = 2.50%, \n",
      "MACs Reduction = 2.78%, \n",
      "Weighted Importance Score = 0.81\n",
      "Block 20: Accuracy Decrease Contribution = 1.35%, \n",
      "Parameter Reduction = 2.50%, \n",
      "MACs Reduction = 2.78%, \n",
      "Weighted Importance Score = 0.67\n",
      "Block 21: Accuracy Decrease Contribution = 1.35%, \n",
      "Parameter Reduction = 2.50%, \n",
      "MACs Reduction = 2.78%, \n",
      "Weighted Importance Score = 0.67\n",
      "Block 22: Accuracy Decrease Contribution = 0.81%, \n",
      "Parameter Reduction = 2.50%, \n",
      "MACs Reduction = 2.78%, \n",
      "Weighted Importance Score = 0.40\n",
      "Block 23: Accuracy Decrease Contribution = 0.27%, \n",
      "Parameter Reduction = 2.50%, \n",
      "MACs Reduction = 2.78%, \n",
      "Weighted Importance Score = 0.13\n",
      "Block 24: Accuracy Decrease Contribution = 1.62%, \n",
      "Parameter Reduction = 2.50%, \n",
      "MACs Reduction = 2.78%, \n",
      "Weighted Importance Score = 0.81\n",
      "Block 25: Accuracy Decrease Contribution = 0.54%, \n",
      "Parameter Reduction = 2.50%, \n",
      "MACs Reduction = 2.78%, \n",
      "Weighted Importance Score = 0.27\n",
      "Block 26: Accuracy Decrease Contribution = 1.35%, \n",
      "Parameter Reduction = 2.50%, \n",
      "MACs Reduction = 2.78%, \n",
      "Weighted Importance Score = 0.67\n",
      "Block 27: Accuracy Decrease Contribution = 1.62%, \n",
      "Parameter Reduction = 2.50%, \n",
      "MACs Reduction = 2.78%, \n",
      "Weighted Importance Score = 0.81\n",
      "Block 28: Accuracy Decrease Contribution = 1.35%, \n",
      "Parameter Reduction = 2.50%, \n",
      "MACs Reduction = 2.78%, \n",
      "Weighted Importance Score = 0.67\n",
      "Block 29: Accuracy Decrease Contribution = 1.35%, \n",
      "Parameter Reduction = 2.50%, \n",
      "MACs Reduction = 2.78%, \n",
      "Weighted Importance Score = 0.67\n",
      "Block 30: Accuracy Decrease Contribution = 0.00%, \n",
      "Parameter Reduction = 2.50%, \n",
      "MACs Reduction = 2.78%, \n",
      "Weighted Importance Score = 0.00\n",
      "Block 31: Accuracy Decrease Contribution = -0.81%, \n",
      "Parameter Reduction = 2.50%, \n",
      "MACs Reduction = 2.78%, \n",
      "Weighted Importance Score = -0.40\n",
      "Block 32: Accuracy Decrease Contribution = 0.00%, \n",
      "Parameter Reduction = 2.50%, \n",
      "MACs Reduction = 2.78%, \n",
      "Weighted Importance Score = 0.00\n",
      "Block 33: Accuracy Decrease Contribution = 0.27%, \n",
      "Parameter Reduction = 2.50%, \n",
      "MACs Reduction = 2.78%, \n",
      "Weighted Importance Score = 0.13\n",
      "Block 34: Accuracy Decrease Contribution = 1.08%, \n",
      "Parameter Reduction = 2.50%, \n",
      "MACs Reduction = 2.78%, \n",
      "Weighted Importance Score = 0.54\n",
      "Block 35: Accuracy Decrease Contribution = 0.00%, \n",
      "Parameter Reduction = 0.00%, \n",
      "MACs Reduction = 0.00%, \n",
      "Weighted Importance Score = 0.00\n",
      "Block 36: Accuracy Decrease Contribution = 0.54%, \n",
      "Parameter Reduction = 10.01%, \n",
      "MACs Reduction = 2.78%, \n",
      "Weighted Importance Score = 0.27\n",
      "Block 37: Accuracy Decrease Contribution = 0.54%, \n",
      "Parameter Reduction = 10.01%, \n",
      "MACs Reduction = 2.78%, \n",
      "Weighted Importance Score = 0.27\n",
      "Block 38: Accuracy Decrease Contribution = 0.00%, \n",
      "Parameter Reduction = 10.01%, \n",
      "MACs Reduction = 2.78%, \n",
      "Weighted Importance Score = 0.00\n",
      "Block 39: Accuracy Decrease Contribution = 0.00%, \n",
      "Parameter Reduction = 0.00%, \n",
      "MACs Reduction = 0.00%, \n",
      "Weighted Importance Score = 0.00\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "relative_contribution = perplexity_analysis_with_contributions(model, 'Taylor', cal_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4efc6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pruning_ratios = calculate_pruning_ratios_intense(relative_contribution, max_pruning_ratio=0.5, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "67c05312",
   "metadata": {},
   "outputs": [],
   "source": [
    "pruning_ratios = [np.float64(0.02),\n",
    " np.float64(0.4),\n",
    " np.float64(0.3),\n",
    " np.float64(0.47),\n",
    " np.float64(0.44),\n",
    " np.float64(0.43),\n",
    " np.float64(0.44),\n",
    " np.float64(0.47),\n",
    " np.float64(0.49),\n",
    " np.float64(0.44),\n",
    " np.float64(0.45),\n",
    " np.float64(0.43),\n",
    " np.float64(0.44),\n",
    " np.float64(0.49),\n",
    " np.float64(0.44),\n",
    " np.float64(0.5),\n",
    " np.float64(0.48),\n",
    " np.float64(0.43),\n",
    " np.float64(0.46),\n",
    " np.float64(0.44),\n",
    " np.float64(0.44),\n",
    " np.float64(0.44),\n",
    " np.float64(0.45),\n",
    " np.float64(0.47),\n",
    " np.float64(0.44),\n",
    " np.float64(0.46),\n",
    " np.float64(0.44),\n",
    " np.float64(0.44),\n",
    " np.float64(0.44),\n",
    " np.float64(0.44),\n",
    " np.float64(0.47),\n",
    " np.float64(0.49),\n",
    " np.float64(0.47),\n",
    " np.float64(0.47),\n",
    " np.float64(0.45),\n",
    " np.float64(0.47),\n",
    " np.float64(0.46),\n",
    " np.float64(0.46),\n",
    " np.float64(0.47),\n",
    " np.float64(0.47)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a21c32e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accumulating gradients for pruning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:16<00:00, 63.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MACs of the Original Model: 15.360289896 G  -->  MACs of the Pruned Model: 8.893172991 G\n",
      "# Parameters of the Original Model: 88591.464 K  --> # Parameters of the Pruned Model: 50298.111 K\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "pruned_model = prune_model(model, 'Taylor', pruning_ratios, cal_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6f73144d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvNeXt(\n",
       "  (stem): Sequential(\n",
       "    (0): Conv2d(3, 128, kernel_size=(4, 4), stride=(4, 4))\n",
       "    (1): LayerNorm2d((128,), eps=1e-06, elementwise_affine=True)\n",
       "  )\n",
       "  (stages): Sequential(\n",
       "    (0): ConvNeXtStage(\n",
       "      (downsample): Identity()\n",
       "      (blocks): Sequential(\n",
       "        (0): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)\n",
       "          (norm): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (shortcut): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (1): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)\n",
       "          (norm): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (shortcut): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (2): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)\n",
       "          (norm): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (shortcut): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): ConvNeXtStage(\n",
       "      (downsample): Sequential(\n",
       "        (0): LayerNorm2d((128,), eps=1e-06, elementwise_affine=True)\n",
       "        (1): Conv2d(128, 256, kernel_size=(2, 2), stride=(2, 2))\n",
       "      )\n",
       "      (blocks): Sequential(\n",
       "        (0): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)\n",
       "          (norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (shortcut): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (1): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)\n",
       "          (norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (shortcut): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (2): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)\n",
       "          (norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (shortcut): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): ConvNeXtStage(\n",
       "      (downsample): Sequential(\n",
       "        (0): LayerNorm2d((256,), eps=1e-06, elementwise_affine=True)\n",
       "        (1): Conv2d(256, 512, kernel_size=(2, 2), stride=(2, 2))\n",
       "      )\n",
       "      (blocks): Sequential(\n",
       "        (0): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (shortcut): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (1): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (shortcut): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (2): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (shortcut): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (3): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (shortcut): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (4): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (shortcut): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (5): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (shortcut): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (6): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (shortcut): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (7): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (shortcut): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (8): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (shortcut): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (9): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (shortcut): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (10): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (shortcut): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (11): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (shortcut): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (12): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (shortcut): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (13): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (shortcut): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (14): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (shortcut): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (15): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (shortcut): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (16): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (shortcut): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (17): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (shortcut): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (18): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (shortcut): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (19): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (shortcut): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (20): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (shortcut): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (21): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (shortcut): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (22): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (shortcut): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (23): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (shortcut): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (24): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (shortcut): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (25): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (shortcut): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (26): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (shortcut): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): ConvNeXtStage(\n",
       "      (downsample): Sequential(\n",
       "        (0): LayerNorm2d((512,), eps=1e-06, elementwise_affine=True)\n",
       "        (1): Conv2d(512, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
       "      )\n",
       "      (blocks): Sequential(\n",
       "        (0): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)\n",
       "          (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (shortcut): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (1): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)\n",
       "          (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (shortcut): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (2): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)\n",
       "          (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (shortcut): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (norm_pre): Identity()\n",
       "  (head): NormMlpClassifierHead(\n",
       "    (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Identity())\n",
       "    (norm): LayerNorm2d((1024,), eps=1e-06, elementwise_affine=True)\n",
       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "    (pre_logits): Identity()\n",
       "    (drop): Dropout(p=0.0, inplace=False)\n",
       "    (fc): Linear(in_features=1024, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a4b4522d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvNeXt(\n",
       "  (stem): Sequential(\n",
       "    (0): Conv2d(3, 128, kernel_size=(4, 4), stride=(4, 4))\n",
       "    (1): LayerNorm2d((128,), eps=1e-06, elementwise_affine=True)\n",
       "  )\n",
       "  (stages): Sequential(\n",
       "    (0): ConvNeXtStage(\n",
       "      (downsample): Identity()\n",
       "      (blocks): Sequential(\n",
       "        (0): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)\n",
       "          (norm): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=128, out_features=501, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=501, out_features=128, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (shortcut): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (1): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)\n",
       "          (norm): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=128, out_features=307, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=307, out_features=128, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (shortcut): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (2): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)\n",
       "          (norm): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=128, out_features=358, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=358, out_features=128, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (shortcut): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): ConvNeXtStage(\n",
       "      (downsample): Sequential(\n",
       "        (0): LayerNorm2d((128,), eps=1e-06, elementwise_affine=True)\n",
       "        (1): Conv2d(128, 256, kernel_size=(2, 2), stride=(2, 2))\n",
       "      )\n",
       "      (blocks): Sequential(\n",
       "        (0): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)\n",
       "          (norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=256, out_features=573, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=573, out_features=256, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (shortcut): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (1): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)\n",
       "          (norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=256, out_features=583, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=583, out_features=256, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (shortcut): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (2): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)\n",
       "          (norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=256, out_features=573, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=573, out_features=256, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (shortcut): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): ConvNeXtStage(\n",
       "      (downsample): Sequential(\n",
       "        (0): LayerNorm2d((256,), eps=1e-06, elementwise_affine=True)\n",
       "        (1): Conv2d(256, 512, kernel_size=(2, 2), stride=(2, 2))\n",
       "      )\n",
       "      (blocks): Sequential(\n",
       "        (0): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=512, out_features=1044, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=1044, out_features=512, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (shortcut): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (1): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=512, out_features=1146, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=1146, out_features=512, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (shortcut): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (2): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=512, out_features=1126, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=1126, out_features=512, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (shortcut): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (3): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=512, out_features=1167, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=1167, out_features=512, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (shortcut): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (4): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=512, out_features=1146, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=1146, out_features=512, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (shortcut): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (5): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=512, out_features=1044, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=1044, out_features=512, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (shortcut): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (6): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=512, out_features=1146, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=1146, out_features=512, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (shortcut): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (7): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=512, out_features=1024, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=1024, out_features=512, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (shortcut): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (8): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=512, out_features=1064, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=1064, out_features=512, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (shortcut): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (9): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=512, out_features=1167, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=1167, out_features=512, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (shortcut): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (10): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=512, out_features=1105, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=1105, out_features=512, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (shortcut): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (11): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=512, out_features=1146, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=1146, out_features=512, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (shortcut): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (12): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=512, out_features=1146, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=1146, out_features=512, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (shortcut): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (13): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=512, out_features=1146, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=1146, out_features=512, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (shortcut): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (14): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=512, out_features=1126, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=1126, out_features=512, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (shortcut): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (15): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=512, out_features=1085, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=1085, out_features=512, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (shortcut): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (16): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=512, out_features=1146, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=1146, out_features=512, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (shortcut): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (17): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=512, out_features=1105, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=1105, out_features=512, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (shortcut): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (18): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=512, out_features=1146, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=1146, out_features=512, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (shortcut): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (19): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=512, out_features=1146, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=1146, out_features=512, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (shortcut): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (20): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=512, out_features=1146, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=1146, out_features=512, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (shortcut): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (21): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=512, out_features=1146, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=1146, out_features=512, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (shortcut): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (22): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=512, out_features=1085, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=1085, out_features=512, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (shortcut): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (23): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=512, out_features=1044, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=1044, out_features=512, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (shortcut): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (24): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=512, out_features=1085, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=1085, out_features=512, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (shortcut): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (25): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=512, out_features=1085, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=1085, out_features=512, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (shortcut): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (26): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=512, out_features=1126, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=1126, out_features=512, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (shortcut): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): ConvNeXtStage(\n",
       "      (downsample): Sequential(\n",
       "        (0): LayerNorm2d((512,), eps=1e-06, elementwise_affine=True)\n",
       "        (1): Conv2d(512, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
       "      )\n",
       "      (blocks): Sequential(\n",
       "        (0): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)\n",
       "          (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=2211, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=2211, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (shortcut): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (1): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)\n",
       "          (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=2211, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=2211, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (shortcut): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (2): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)\n",
       "          (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=2170, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=2170, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (shortcut): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (norm_pre): Identity()\n",
       "  (head): NormMlpClassifierHead(\n",
       "    (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Identity())\n",
       "    (norm): LayerNorm2d((1024,), eps=1e-06, elementwise_affine=True)\n",
       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "    (pre_logits): Identity()\n",
       "    (drop): Dropout(p=0.0, inplace=False)\n",
       "    (fc): Linear(in_features=1024, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruned_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dd4df63e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [04:02<00:00, 205.84it/s]\n"
     ]
    }
   ],
   "source": [
    "pruned_accuracy,_ = validate_model(pruned_model, val_loader, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b2d2c4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(pruned_model, '/home/ict317-3/Mohammad/Isomorphic-Pruning/our_pruned_models/ConvNext4.2/pruned_model_43%.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
